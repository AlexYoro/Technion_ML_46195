### הגישה הדיסקרימינטיבית הסתברותית

בגישה הגנרטיבית ניסינו ללמוד את הפילוג המשותף $p_{\mathbf{x},\text{y}}(\boldsymbol{x},y)$ מתוך המדגם כאשר בפועל אנו נהיה מעוניינים לרוב לדעת רק את הפילוג המותנה $p_{\text{y}|\mathbf{x}}(y|\boldsymbol{x})$. כפי שראינו, במרבית המקרים, הידיעה של $p_{\text{y}|\mathbf{x}}(y|\boldsymbol{x})$ מספיקה לנו בכדי לבנות את החזאי האופטימאלי. בגישה הדיסקרימנטיבית הסתברותית, אנו נבחר מודל פרמטרי ל $p_{\text{y}|\mathbf{x}}(y|\boldsymbol{x};\boldsymbol{\theta})$ ונתאים את הפרמטרים של המודל למדגם בעזרת שיטות כדוגמאת MLE או MAP.

המשימה של ללמוד רק את הפילוג המותנה $p_{\text{y}|\mathbf{x}}(y|\boldsymbol{x})$ תהיה לרוב משימה פשוטה יותר מאשר המשימה של ללמוד את הפילוג המשותף $p_{\mathbf{x},\text{y}}(\boldsymbol{x},y)$ מכיוון שאנו כבר לא מנסים ללמוד מהו הפילוג של $\mathbf{x}$. ההדבל בין שתי המשימות נהיה משמעותי בעיקר בעיות סיווג (בהם $\text{y}$ בדיד וסופי) שם ניתן בקלות יתרה לבנות מודלים פרמטריים אשר מהווים פונקציית פילוג חוקית.

**הערה לגבי השם**: משום שגישה זו לא מנסה ללמוד את הפילוג המלא של מדגם היא נחשבת לגישה דיסקרימינטיבית למרות שבאופי שלה היא מאד קרובה לגישה הגנרטיבית. ישנם מקומות לא עושים הבחנה בין הגישה הדיסקרימינטיבית אותה למדנו בתחילת הקורס (בה ניסינו ללמוד ישירות את החזאי בלי לעבור דרך אף פונקציית פילוג) והגישה הזו. בקרוס זה אנו נתייחס אליהם כאל שתי גישות שונות שהדמיון בינהם הוא רק בשם.

### פונקציית ה Softmax

פונקציית ה softmax לוקחת וקטור כלשהו $\boldsymbol{z}$ באורך $C$ ומייצרת ממנו וקטור חדש אשר יכול לייצג פילוג דיסקרטי חוקי של משתנה אשר מקבל אחד מ $C$ ערכים. היא עושה באופן הבא:

1. על מנת להפוך את כל רכיבי הוקטור לחיוביים, כל איבר בוקטור $z_i$ מוחלף באקפוננט שלו $e^{z_i}$.
2. בכדי שסכום הערכים של הוקטור יהיה אחד מנרמלים את הוקטור על ידי חלוקת איברי הוקטור בסכום האיברים: $\sum_i e^{z_i}$.

מקובל לסמן את פעולת בסה"כ פועלת ה softmax מייצרת וקטור אשר האיבר ה $i$ שלו נתון על ידי:

$$
\text{softmax}(\boldsymbol{z})_i=\frac{e^{z_i}}{\sum_{j=1}^C e^{z_j}}
$$

#### מספר תכונות של פונקציית ה Softmax:

- אינווריאנטיות לתוספת של קבוע (לכל אברי הוקטור): $\text{softmax}(\boldsymbol{z} + a)_i=\text{softmax}(\boldsymbol{z})_i\ \forall i$.
- $\frac{\partial}{\partial z_j} \log(\text{softmax}(\boldsymbol{z}))_i=\underbrace{\delta_{i,j}}_{=I\{i=j\}}-\text{softmax}(\boldsymbol{z})_j$

### Logistic Regression

בניגוד לשם, logistic regression היא שיטה לפתרון בעיות סיווג בגישה הדיסקרימינטיבית הסתברותית. בשיטה זו אנו נבחר $C$ פונקציות פרמטריות כל שהם $f_c(\boldsymbol{x};\boldsymbol{\theta}_c)$ ונמדל את הפילוג המותנה באופן הבא:

$$
p_{\text{y}|\mathbf{x}}(y|\boldsymbol{x};\boldsymbol{\theta})
=\text{softmax}(\boldsymbol{f}(\boldsymbol{x};\boldsymbol{\theta}))_{y}
=\frac{e^{f_y(\boldsymbol{x};\boldsymbol{\theta}_y)}}{\sum_{c=1}^C e^{f_c(\boldsymbol{x};\boldsymbol{\theta}_c)}}
$$

(הוקטור $\boldsymbol{\theta}$ הוא וקטור המכיל את כל הפרמטרים של כל $C$ הפונקציות הפרמטריות: $\boldsymbol{\theta}=[\boldsymbol{\theta}_1^{\top},\boldsymbol{\theta}_2^{\top},\dots,\boldsymbol{\theta}_C^{\top}]^{\top}$)

את הפרמטרים של המודל ניתן למצוא בעזרת MLE, אשר נותן את בעיית האופטימיזציה הבאה:

$$
\boldsymbol{\theta}^*
=\underset{\boldsymbol{\theta}}{\arg\min}\ -\sum_{i=1}^N \log p_{\text{y}|\mathbf{x}}(y^{(i)}|\boldsymbol{x}^{(i)};\boldsymbol{\theta})
=\underset{\boldsymbol{\theta}}{\arg\min}\ -\sum_{i=1}^N \log\left(\text{softmax}(\boldsymbol{f}(\boldsymbol{x};\boldsymbol{\theta}))_{y}\right)
$$

לבעיית אופטימיזציה זו אין פתרון סגור והיא לרוב תיפתר בעזרת gradient descent.

#### ביטול היתירות של המודל

בגלל האינווריאנטיות של פונקציית ה softmax לכל תוספת אשר מתווספת לכל איברי הוקטור כל שינוי של הפונקציות הפרמטריות מהצורה של $f_c(\boldsymbol{x};\boldsymbol{\theta}_c)\rightarrow f_c(\boldsymbol{x};\boldsymbol{\theta}_c)+g(\boldsymbol{x})$ לא תשנה את הפילוג $p_{\text{y}|\mathbf{x}}(y|\boldsymbol{x})$. המשמעות של הדבר, הינה שישנה יותר מדרך אחת לייצג כל פילוג, תכונה שהיא לרוב לא רצויה. הדרך הנפוצה לבטל יתירות זו הינה על ידי קבוע אחת הפונקציות הפרמטריות, לרוב הראשונה $c=1$, להיות שווה זהותית 0: $f_1(\boldsymbol{x};\boldsymbol{\theta}_1)=0$ . שינוי שכזה לא יפגע ביכולת הייצוג של המודל ויבטל את היתירות שיש בייצוג של כל פילוג. בחירה כזו גם תקטין את מספר הפרמטרים שיש ללמוד.

#### המקרה הבינארי

נסתכל על המקרה שבו ישנם רק שתי מחלקות ($C=2$). נסמן את שתי המחלקות ב 0 ו 1. בכדי לבטל את היתירות נקבע את הפונקציה הפרמטריות שהייתה אמורה לתאים ל $c=0$ להיות זהותית 0: $f_0(\boldsymbol{x})=0$. נקבל אם כן את המודל הפרמטרי הבא:

$$
p_{\text{y}|\mathbf{x}}(0|\boldsymbol{x};\boldsymbol{\theta})
=\frac{1}{1+e^{f(\boldsymbol{x};\boldsymbol{\theta})}}
$$

$$
p_{\text{y}|\mathbf{x}}(1|\boldsymbol{x};\boldsymbol{\theta})
=\frac{e^{f(\boldsymbol{x};\boldsymbol{\theta})}}{e^{f(\boldsymbol{x};\boldsymbol{\theta})}+1}
=\frac{1}{1+e^{-f(\boldsymbol{x};\boldsymbol{\theta})}}
$$

הפונקציה:

$$
\sigma(z)=\frac{1}{1+e^{-z}}
$$

נקראת **הפונקציה הלוגיסטית (logistic function)** והיא נראית כך:

בהקשר של רשתות נוירונים פונקציה זו מכונה לרוב פונקציית ה**סיגמואיד (sigmoid)** (למרות שמבחינת ההגדרה המתטתית סיגמואיד היא כל פונקציה בעלת צורה של S).

בעזרת הפונקציה הלוגיסטית נוכל לרשום את המודל במקרה הבינארי באופן הבא:

$$
p_{\text{y}|\mathbf{x}}(0|\boldsymbol{x};\boldsymbol{\theta})=\sigma(-f(\boldsymbol{x};\boldsymbol{\theta}))=1-\sigma(f(\boldsymbol{x};\boldsymbol{\theta}))
$$

$$
p_{\text{y}|\mathbf{x}}(1|\boldsymbol{x};\boldsymbol{\theta})=\sigma(f(\boldsymbol{x};\boldsymbol{\theta}))
$$

#### רגרסיה לוגיסטית לינארית

הגרסא הלינארית של הרגרסיה הלוגיסטית היא המקרה שבו בוחרים את הפונקציות הפרמטריות להיות פונקציות לינאריות:

$$
f_c(\boldsymbol{x};\boldsymbol{\theta}_c)=\boldsymbol{\theta}_c^{\top}\boldsymbol{x}
$$

במקרה זה פונקציית ה objective היא קמורה (convex) ולכן מובטח שיהיה רק מינימום יחיד וש gradient descnet, במידה והוא מתכנס, יתכנס למינימום הגלובלי.

### Gradient descent (שיטת הגרדיאנט)

Gradient descent מנסה למצוא מינימום לוקאלי של ה objective, $g(\boldsymbol{\theta})$, על ידי כך שהוא מתחיל בנקודה אקראית כל שהיא במרחב ואז מתקדם בצעדים קטנים בכיוון ההפוך מהגרדיאנט, שהוא הכיוון שבו ה objective קטן בקצב המהיר ביותר. זהו אלגוריתם חמדן (greedy) אשר מנסה בכל צעד לשפר במעט את מצבו ביחס לשלב הקודם.

#### האלגוריתם

- מאתחלים את $\boldsymbol{\theta}^{(0)}$ בנקודה אקראית כל שהיא
- חוזרים על צעד העדכון הבא עד שמתקיים תנאי עצירה כל שהוא:

    $$
    \boldsymbol{\theta}^{(t+1)}=\boldsymbol{\theta}^{(t)}-\eta \nabla_{\boldsymbol{\theta}}g(\boldsymbol{\theta}^{(t)})
    $$

הפרמטר $\eta$ אשר קובע את גודל הצעדים אשר נעשה בתהליך ההתכנסות.

#### תנאי עצירה

ישנם מספר דרכים לגדיר תנאי עצירה לאגוריתם:

- הגעה למספר צעדי עדכון שנקבע מראש: $t>\text{max-iter}$.
- כאשר הנורמה של הגרדיאנט קטנה מתחת לערך סף מסויים שנקבע מראש: $\lVert\nabla_{\boldsymbol{\theta}}g(\boldsymbol{\theta})\rVert_2<\epsilon$
- כאשר השיפור ב objective קטן מערך סף מסויים שנקבע מראש: $g(\boldsymbol{\theta}^{(t-1)})-g(\boldsymbol{\theta}^{(t)})<\epsilon$
- שימוש בעצירה מוקדמת על מנת להתמודד עם overfitting.

#### שימוש בעצירה מוקדמת על מנת להתמודד עם overfitting.

ניתן לנסות ולעצור את האלגוריתם לפני שהוא מתכנס למינימום על מנת לנסות והקטין את תופעת ה overfitting. ניתן לעשות זאת על ידי שימוש ב validation set ולבדוק מתי הביצועים על ה validation מתחילים להיפגע. שיטה זו מכונה עצירה מודקמת (early stopping).

#### הבעיה של גודל הצעד של האלגוריתם

לרוב אלגוריתם הגרדיאנט בצורתו הפשוטה הוא מאד בעייתי בעיקר משום הקושי למצוא גודל צעד $\eta$ אפקטיבי:

- $\eta$ קטן יגרום לאלגוריתם להתכנס בצורה מאד איטית כך שידרשו למספר גדול ולא פרקטי של צעדים.
- $\eta$ גדול ימנע מהאלגוריתם מלהתכנס (כפי שנראה בתרגיל ...) ובמרבית המקרים אף להתבדר.

(במקרים רבים לאלגוריתם הפשוט לא יהיה ערך ביניים אפקטיבי)

#### Stochastic Gradient Descent

stochastic gradient descent מתאים למקרים שבו ה objective הוא מהצורה של סכום שרץ על כל הדגימות במדגם (או ב train set). במקרים כאלה ניתן לבצע קירוב גס של הגרדיאנט על ידי בחירה אקראית של דגימה בודדת מהמדגם בכל צעד. (לחילופין ניתן להשתמש בכל פעם בדגימה אחרת מהדגם באופן סידרתי).